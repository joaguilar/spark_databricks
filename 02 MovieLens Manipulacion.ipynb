{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9238aa7a-72d4-4d7f-aeb4-c51ce71ba0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init('/spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa200c7d-2701-4b05-85ee-496e9d90b715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Sesion\n",
    "\n",
    "Lo primero siempre es crear la sesion de Spark. La sesion permite a todos los procesos involucrados compartir contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7700cc4-ad50-45c2-a039-98b4d9e79640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.appName(\"movielens\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2252dcd-2472-412c-a89d-613a73264b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Carga de datos\n",
    "\n",
    "En la siguiente celda realizamos la carga de los datos del dataset de Movielens. en este caso vamos a cargar 3 de las tablas:\n",
    "\n",
    "* ratings\n",
    "* movies\n",
    "* tags\n",
    "\n",
    "Para esto definimos primero los schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f4ad5d-77d8-4e3c-95c1-23d351a0a252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratingsDf = spark.read.csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/ratings.csv\")\n",
    "moviesDf = spark.read.csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/movies.csv\")\n",
    "tagsDf = spark.read.csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbdc3a3-fa1f-40e7-897e-9ad25ba23057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Revisamos primero el dataframe de ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed394a6b-6fbc-456d-bb94-a91453eec661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd16f0b-c7ab-4673-9cbd-c1cdfb8cc663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratingsDf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8437c943-2590-4336-9c32-956d2e7fa54e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Vemos que tiene header, y los tipos de datos, incluyendo el ultimo que es un timestamp. Podemos definir el schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad40a323-b99d-4d46-a1d1-b49ba96e36b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratings_schema  = StructType(fields=[\n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True),\n",
    "    StructField(\"rating\",DecimalType(precision=2,scale=1),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f323e8-0513-4576-95bd-c89bb9ed4282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratingsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"dateFormat\", \"yyyyMMdd\")\\\n",
    "    .schema(ratings_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/ratings.csv\")\n",
    "ratingsDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c46653c5-6941-4134-a251-2fd10d70ff30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b20e80-23eb-4289-8afd-427df548aba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_schema  = StructType(fields=[\n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"title\",StringType(),True),\n",
    "    StructField(\"genres\",StringType(),True)\n",
    "])\n",
    "\n",
    "moviesDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(movies_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/movies.csv\")\n",
    "moviesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f84c2b6-4798-4abb-9603-014d5908cdd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54b9ed99-7b7e-42c5-a084-cbaeebdc79ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notamos dos cosas:\n",
    "\n",
    "1. En la columna `genres` vienen multiples valores separados por `|`\n",
    "1. En la columna `title` viene tanto el nombre de la palicula como el año en que salió\n",
    "\n",
    "Queremos separar esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f29ab43-5601-4717-aaa9-4e3c62b96b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# La función spli separa una columna en un arreglo\n",
    "moviesDf.select(split(col(\"genres\"),\"\\|\").alias(\"genresSplit\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35aec027-8e9e-4b3e-8025-8c6f9ceedd53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O de otra forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e56d96-2f2f-470b-9b7c-5810088a3684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDf.withColumn(\"genresSplit\", split(moviesDf[\"genres\"],\"\\|\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d856ee6-0d82-469f-9cb7-3ebefd0fd73c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDf.withColumn(\"genresSplit\", split(moviesDf[\"genres\"],\"\\|\"))\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e722d35-b367-494b-8fb5-9e329940cf1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "No es necesario mantener ambas columnas, entonces es posible eliminar la columna `genres`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5ae7f7-ef27-40e1-9b0d-6e29af1c8304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.drop(\"genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae5ba299-4682-4823-a391-d203e9727472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ahora revisamos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9ae6f5-2a53-4bea-a3f9-a5365ca5d8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880826b6-a615-476b-8226-095c0fa20c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Los dataframes son inmutables, por lo que vimos anteriormente fue un nuevo dataframe. Para conservar el cambio tenemos que asignarlo para ver el cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a227daab-a20c-44be-8baa-de8f71102075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDfSplit.drop(\"genres\")\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a2c773-0077-414f-bd5f-152328f3a546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ahora sucede lo mismo con la columna title. Podemos extrar el nombre de la película y el año y crear columnas especificas para cada dato. Usamos expresiones regulares con la funcion [regexp_extract](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract.html#pyspark.sql.functions.regexp_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "371c4784-8742-47a2-b5ee-64f9aa5ce250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce04419-5424-42c8-bef9-587e43ccfec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Revisamos el schema y vemos que es de tipo string, deberia ser numerico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa26650-65e1-4380-9181-c4c4da1232a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1)).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ecc777-c9f4-4aff-b52d-f6481bcc2582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1).cast(IntegerType())).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd17be47-3af6-4864-b3bf-81276528135a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1).cast(IntegerType())).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2319df8a-70b3-4005-86b3-756a1dc1cc91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDfSplit\\\n",
    "                .withColumn(\\\n",
    "                            \"year\",\\\n",
    "                            regexp_extract(\\\n",
    "                                           moviesDf[\"title\"],\\\n",
    "                                           \"^.+\\(([0-9]+)\\)$\",\\\n",
    "                                           1)\\\n",
    "                            .cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a76ae5b9-b860-4c2d-a7f9-33efcd323362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Existen muchas funciones similares que se pueden utilizar, la documentación está en [Spark SQL Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ba95fc-8ed9-4608-9a3a-fb33f3f86038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a350d2-72c5-44a1-9d4f-7359e3f7db37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Hacemos lo mismo para obtener el titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa54074-0290-428a-90fa-7cc9dac40fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,regexp_extract\n",
    "\n",
    "moviesDfSplit=moviesDfSplit\\\n",
    "                .withColumn(\\\n",
    "                            \"title_temp\",\\\n",
    "                            regexp_extract(\\\n",
    "                                           col(\"title\"),\\\n",
    "                                           \"^(.+?) \\([0-9]+\\)$\",\\\n",
    "                                           1))\\\n",
    "                .drop('title')\\\n",
    "                .withColumnRenamed(\"title_temp\",\"title\")\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdbf54b-d46d-4cc4-bab6-468e92e51caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b701a517-84ac-46b1-ae13-66fdea0cb370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Por ultimo hacemos lo mismo con la tabla de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e33103c3-dd76-4ad8-869d-70fd1132a7d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80af7be-991e-4f85-bf85-63c670c2550e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_schema  = StructType(fields=[    \n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"tag\",StringType(),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])\n",
    "\n",
    "tagsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(tags_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/tags.csv\")\n",
    "\n",
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83aa8ed-2b39-47af-8ea1-ddaa977785d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagsDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab766ed-bfbb-46c3-9d62-cd5eff46c9d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94515f1c-c630-4118-a702-f10ea8e37ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagsDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b7cafc3-26ca-4310-add0-e3f3d343cef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finalmente, convertimos el timestamp en una fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17c06560-9eeb-474e-977d-0838587dafa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime\n",
    "\n",
    "\n",
    "tags_schema  = StructType(fields=[    \n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"tag\",StringType(),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])\n",
    "\n",
    "tagsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(tags_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/tags.csv\")\n",
    "\n",
    "\n",
    "tagsDf=tagsDf\\\n",
    "        .withColumn(\\\n",
    "            \"date\",\\\n",
    "            from_unixtime(\"timestamp\", \"yyyyMMdd\"))\\\n",
    "                .drop('timestamp')\n",
    "\n",
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13ffb10f-d0f8-4348-ade3-33fcb00fea6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02 MovieLens Manipulacion",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
