{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b276de4-63c6-4748-a932-523f5f4a2785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max, desc\n",
    "from pyspark.sql.functions import grouping, explode, array_contains, struct, collect_list, row_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4964f37-a384-482c-826e-225bf36dbfad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformaciones con Tipos de Datos Complejos: Arrays, Structs y Maps\n",
    "\n",
    "En este notebook:\n",
    "- Trabajaremos con columnas tipo array y struct a partir del dataset MovieLens.\n",
    "- Aplicaremos funciones como `explode`, y crearemos structs de varias columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f5b7391-b94f-412e-a61d-e786c3dac5f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tabla Ratings\n",
    "ratings_schema  = StructType(fields=[\n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True),\n",
    "    StructField(\"rating\",DecimalType(precision=2,scale=1),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])\n",
    "ratingsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"dateFormat\", \"yyyyMMdd\")\\\n",
    "    .schema(ratings_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/ratings_full.csv\")\\\n",
    "    .withColumn(\\\n",
    "            \"date\",\\\n",
    "            from_unixtime(\"timestamp\", \"yyyyMMdd\"))\\\n",
    "                .drop('timestamp')\n",
    "\n",
    "# Tabla Movies\n",
    "movies_schema  = StructType(fields=[\n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"title\",StringType(),True),\n",
    "    StructField(\"genres\",StringType(),True)\n",
    "])\n",
    "\n",
    "moviesDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(movies_schema)\\\n",
    "    .csv(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/movies.csv\")\n",
    "\n",
    "moviesDf = moviesDf.withColumn(\"genresSplit\", split(moviesDf[\"genres\"],\"\\|\"))\\\n",
    "                        .drop('genres').withColumnRenamed(\"genresSplit\",\"genres\")\\\n",
    "                            .withColumn(\\\n",
    "                                \"year\",\\\n",
    "                                regexp_extract(\\\n",
    "                                           moviesDf[\"title\"],\\\n",
    "                                           \"^.+\\(([0-9]+)\\)$\",\\\n",
    "                                           1)\\\n",
    "                                .try_cast(IntegerType()))\\\n",
    "                            .withColumn(\\\n",
    "                            \"title_temp\",\\\n",
    "                            regexp_extract(\\\n",
    "                                           moviesDf[\"title\"],\\\n",
    "                                           \"^(.+?) \\([0-9]+\\)$\",\\\n",
    "                                           1))\\\n",
    "                            .drop('title')\\\n",
    "                        .withColumnRenamed(\"title_temp\",\"title\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d25cf791-9ff4-4a77-b993-0c163fc7aaad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupar calificaciones por usuario (array de movieIds)\n",
    "user_movies = ratingsDf.groupBy(\"userId\").agg(collect_list(\"movieId\").alias(\"peliculas_calificadas\"))\n",
    "user_movies.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6781c6d1-0e8a-4203-ad88-c9b624f1cac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explode: expandir para tener una fila por usuario/película\n",
    "user_movies_exploded = user_movies.withColumn(\"pelicula_id\", explode(col(\"peliculas_calificadas\")))\n",
    "user_movies_exploded.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376f1596-b5df-4859-94ed-5994ba7edb63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Struct: juntar nombre y género de la película\n",
    "movies_struct = moviesDf.withColumn(\"info\", struct(\"title\", \"genres\"))\n",
    "movies_struct.select(\"movieId\", \"info\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93d1984-9b34-488b-b3c4-d03a07d5384c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crear columna tipo map (clave=movieId, valor=rating) para cada usuario\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "# Ejemplo sencillo: para cada usuario, tomar sus primeras 3 calificaciones y armar el map\n",
    "sample = ratingsDf.filter(col(\"userId\") == 1).limit(3)\n",
    "sample_map = sample.withColumn(\"movie_rating_map\", create_map(col(\"movieId\"), col(\"rating\")))\n",
    "sample_map.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ff9b9b-8642-4fdd-b4db-a50eab0add80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tomemos los 3 primeros ratings de cada usuario para simplicidad\n",
    "w = Window.partitionBy(\"userId\").orderBy(\"date\")\n",
    "ratings_sample = ratingsDf.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") <= 3)\n",
    "\n",
    "# Para cada usuario, agrupamos las (movieId, rating) en una lista de pares\n",
    "user_pairs = ratings_sample.groupBy(\"userId\").agg(collect_list(struct(\"movieId\", \"rating\")).alias(\"peliculas_ratings\"))\n",
    "\n",
    "# Convertimos la lista de structs a una columna Map\n",
    "from pyspark.sql.functions import map_from_entries\n",
    "\n",
    "user_map = user_pairs.withColumn(\"mapa_ratings\", map_from_entries(col(\"peliculas_ratings\")))\n",
    "\n",
    "# Mostramos el resultado: ahora para cada usuario hay un Map movieId->rating\n",
    "user_map.select(\"userId\", \"mapa_ratings\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28cae116-ab4e-462d-956f-d7636ba169ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- USO DEL MAP ---\n",
    "user_map_con_valor = user_map.withColumn(\"rating_pelicula_1\", col(\"mapa_ratings\").getItem(lit(1)))\n",
    "user_map_con_valor.select(\"userId\", \"mapa_ratings\", \"rating_pelicula_1\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2daab5c4-db85-46f2-b9da-5a63aac85eb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Puedes filtrar por los usuarios que hayan calificado la película 1 con rating mayor o igual a 4\n",
    "user_map_con_valor.filter(col(\"rating_pelicula_1\") >= 4).select(\"userId\", \"rating_pelicula_1\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07 Tipos de Datos Complejos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
