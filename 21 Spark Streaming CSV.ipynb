{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90d96151-c7db-4f18-a78a-51f1d4f60423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/people/people.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ef3eb6-1dc5-4ca8-b406-567620c88ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lectura CSVs\n",
    "\n",
    "En este notebook simulamos la lectura de archivos CSV del dataset de _wine quality_ utilizando Structured Streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ba1acb1-4f17-4ea2-aaf6-5c22c0590c79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "\n",
    "wine_schema = StructType([\n",
    "    StructField(\"name\",StringType(),True),\n",
    "    StructField(\"age\",IntegerType(),True)   \n",
    "])\n",
    "\n",
    "streamFiles = (spark.readStream.format(\"cloudFiles\")\n",
    "              .option(\"cloudFiles.format\",\"csv\")\n",
    "              .option(\"header\",\"false\")\n",
    "              .option(\"sep\",\",\")\n",
    "              .option(\"cloudFiles.schemaLocation\", \n",
    "                      \"/Volumes/big_data_ii_2025/spark_examples/schema_people\")\n",
    "              .load(\"/Volumes/big_data_ii_2025/spark_examples/spark_data/people/\"))\n",
    "\n",
    "#Nota: Se le da un directorio, no un archivo, y se pueden agregar archivos posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068afe03-1120-4199-a626-36dc9d638221",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/Volumes/big_data_ii_2025/spark_examples/schema_people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e47f966a-8372-42ec-889c-5f0ec462c555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "El siguiente paso es definir adonde lo vamos a guardar - en este caso creamos una nueva tabla _stream\\_people_.\n",
    "\n",
    "NOTA: Structured Streaming normalmente se utiliza para ingestar datos a la capa bronze del data lake/lakehouse, con un procesamiento muy liviano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25491de3-1c4a-43e9-9fcb-67658e8876ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = (streamFiles.writeStream\n",
    "    .option(\n",
    "    \"checkpointLocation\",\"/Volumes/big_data_ii_2025/spark_examples/chpt_people\")\n",
    "    .trigger(availableNow=True)\n",
    "    .outputMode(\"append\") \n",
    "    .table(\"big_data_ii_2025.spark_examples.stream_people\"))\n",
    "\n",
    "#NOTA: Table retorna un streaming query, no es necesario utilizar la funci√≥n `start()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1888aa0-7f81-43d9-bd84-5658a20cd672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Revisamos el estado:\n",
    "print(q.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf6d982f-e2b8-4847-8626-c1836618f65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ec187a-2f50-49c0-bbfb-f42567d8ccad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM big_data_ii_2025.spark_examples.stream_people"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5640162933447370,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "21 Spark Streaming CSV",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
