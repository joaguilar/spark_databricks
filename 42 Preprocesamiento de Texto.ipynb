{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97383041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==6.0.2 in ./.venv/lib/python3.9/site-packages (6.0.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Requirement already satisfied: wordcloud in ./.venv/lib/python3.9/site-packages (1.9.4)\n",
      "Requirement already satisfied: pypdf2 in ./.venv/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: contractions in ./.venv/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in ./.venv/lib/python3.9/site-packages (from pypdf2) (4.14.1)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in ./.venv/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: anyascii in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spark-nlp==6.0.2 numpy pandas matplotlib seaborn setuptools wordcloud pypdf2 contractions unidecode\n",
    "%pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('./spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max\n",
    "from pyspark.sql.functions import grouping_id, window, explode, to_json, from_json\n",
    "from pyspark.sql.functions import udf, lit, current_timestamp, current_date, date_format\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import PyPDF2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd2c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 15:57:13 WARN Utils: Your hostname, Joses-MacBook-Air-2.local resolves to a loopback address: 127.0.0.1; using 10.105.113.167 instead (on interface en0)\n",
      "25/07/27 15:57:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/joseaguilar/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/joseaguilar/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a08e6fc2-cf0f-480a-8dcf-1851787bd21c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;6.0.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/joseaguilar/Documents/Development/spark/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in local-m2-cache\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in local-m2-cache\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in local-m2-cache\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in local-m2-cache\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.jsoup#jsoup;1.18.2 in central\n",
      "\tfound jakarta.mail#jakarta.mail-api;2.1.3 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;2.1.3 in central\n",
      "\tfound org.eclipse.angus#angus-mail;2.0.3 in central\n",
      "\tfound org.eclipse.angus#angus-activation;2.0.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.2 in central\n",
      "\tfound org.apache.poi#poi;4.1.2 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.4 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound com.zaxxer#SparseBitSet;1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.2 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound org.apache.poi#poi-scratchpad;4.1.2 in central\n",
      "\tfound org.apache.pdfbox#pdfbox;2.0.28 in central\n",
      "\tfound org.apache.pdfbox#fontbox;2.0.28 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.19.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.6 in central\n",
      "\tfound org.jetbrains#annotations;24.1.0 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 in central\n",
      ":: resolution report :: resolve 735ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from local-m2-cache in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from local-m2-cache in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from local-m2-cache in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from local-m2-cache in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;6.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.19.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcom.zaxxer#SparseBitSet;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;2.1.3 from central in [default]\n",
      "\tjakarta.mail#jakarta.mail-api;2.1.3 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.apache.pdfbox#fontbox;2.0.28 from central in [default]\n",
      "\torg.apache.pdfbox#pdfbox;2.0.28 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-scratchpad;4.1.2 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-activation;2.0.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-mail;2.0.3 from central in [default]\n",
      "\torg.jetbrains#annotations;24.1.0 from central in [default]\n",
      "\torg.jsoup#jsoup;1.18.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\tcommons-codec#commons-codec;1.13 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  104  |   0   |   0   |   6   ||   98  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a08e6fc2-cf0f-480a-8dcf-1851787bd21c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 98 already retrieved (0kB/9ms)\n",
      "25/07/27 15:57:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/27 15:57:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/07/27 15:57:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"nlpdemo\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \",\".join([\n",
    "                \"com.johnsnowlabs.nlp:spark-nlp_2.12:6.0.2\"\n",
    "            ])) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397f601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0.2\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 15:57:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer\n",
    "\n",
    "print(sparknlp.version())\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ae0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|texto                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|It's essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!|\n",
      "|I'm going to the store because I can't wait to buy some groceries.                                                   |\n",
      "|El número pi es aproximadamente 3,1416. Ya ahora saben.                                                              |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oraciones = [\n",
    "    \"It's essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!\",\n",
    "    \"I'm going to the store because I can't wait to buy some groceries.\",\n",
    "    \"El número pi es aproximadamente 3,1416. Ya ahora saben.\"\n",
    "]\n",
    "df_oraciones = spark.createDataFrame([(s,) for s in oraciones], [\"texto\"])\n",
    "df_oraciones.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da22100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|texto                                                                                                                |texto_exp                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|It's essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!|It is essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!|\n",
      "|I'm going to the store because I can't wait to buy some groceries.                                                   |I am going to the store because I cannot wait to buy some groceries.                                                  |\n",
      "|El número pi es aproximadamente 3,1416. Ya ahora saben.                                                              |El número pi es aproximadamente 3,1416. Ya ahora saben.                                                               |\n",
      "+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "# Definir una UDF para expandir contracciones en inglés\n",
    "expand_contr = udf(lambda text: contractions.fix(text))\n",
    "df_expanded = df_oraciones.withColumn(\"texto_exp\", expand_contr(col(\"texto\")))\n",
    "df_expanded.select(\"texto\", \"texto_exp\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfdfc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|texto_exp                                                                                                             |texto_limpio                                                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|It is essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!|[it, is, essential, to, drink, coffee, at, a, café, and, to, keep, ones, emotions, in, check, while, analyzing, complex, realtime, data]|\n",
      "|I am going to the store because I cannot wait to buy some groceries.                                                  |[i, am, going, to, the, store, because, i, cannot, wait, to, buy, some, groceries]                                                      |\n",
      "|El número pi es aproximadamente 3,1416. Ya ahora saben.                                                               |[el, número, pi, es, aproximadamente, 31416, ya, ahora, saben]                                                                          |\n",
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import Normalizer\n",
    "\n",
    "normalizer_no_punc = Normalizer()\\\n",
    "    .setInputCols([\"tokenized\"]).setOutputCol(\"document_norm\")\\\n",
    "    .setLowercase(True)\\\n",
    "    .setCleanupPatterns([\"[^\\\\w\\\\sáéíóúÁÉÍÓÚüÜñÑ]\"])  # conservar letras, dígitos y espacios\n",
    "\n",
    "pipeline_norm = Pipeline(stages=[DocumentAssembler().setInputCol(\"texto_exp\").setOutputCol(\"document\"),\n",
    "                                 Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\"),\n",
    "                                 normalizer_no_punc,\n",
    "                                 Finisher().setInputCols([\"document_norm\"]).setOutputCols([\"texto_limpio\"])])\n",
    "df_clean = pipeline_norm.fit(df_expanded).transform(df_expanded)\n",
    "df_clean.select(\"texto_exp\", \"texto_limpio\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878def19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|texto_exp                                                                                                             |texto_sin_acentos                                                                                                     |\n",
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|It is essential to drink coffee at a café and to keep one’s emotions in check while analyzing complex, real-time data!|It is essential to drink coffee at a cafe and to keep one's emotions in check while analyzing complex, real-time data!|\n",
      "|I am going to the store because I cannot wait to buy some groceries.                                                  |I am going to the store because I cannot wait to buy some groceries.                                                  |\n",
      "|El número pi es aproximadamente 3,1416. Ya ahora saben.                                                               |El numero pi es aproximadamente 3,1416. Ya ahora saben.                                                               |\n",
      "+----------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "remove_accents = udf(lambda text: unidecode.unidecode(text))\n",
    "df_no_accents = df_clean.withColumn(\"texto_sin_acentos\", remove_accents(col(\"texto_exp\")))\n",
    "df_no_accents.select(\"texto_exp\", \"texto_sin_acentos\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02cadb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|texto_limpio                                                                                                                            |tokens_final                                                                                                               |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|[it, is, essential, to, drink, coffee, at, a, café, and, to, keep, ones, emotions, in, check, while, analyzing, complex, realtime, data]|[It, essential, drink, coffee, at, a, cafe, keep, one's, emotions, check, while, analyzing, complex, ,, real-time, data, !]|\n",
      "|[i, am, going, to, the, store, because, i, cannot, wait, to, buy, some, groceries]                                                      |[I, going, store, because, I, cannot, wait, buy, groceries, .]                                                             |\n",
      "|[el, número, pi, es, aproximadamente, 31416, ya, ahora, saben]                                                                          |[numero, pi, aproximadamente, 3,1416, ., Ya, ahora, saben, .]                                                              |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, StopWordsCleaner\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1️⃣ DocumentAssembler: convierte texto plano en anotación \"document\"\n",
    "document_assembler = (\n",
    "    DocumentAssembler()\n",
    "    .setInputCol(\"texto_sin_acentos\")   # <- tu columna con texto limpio\n",
    "    .setOutputCol(\"document\")           # ← salida que usará el Tokenizer\n",
    ")\n",
    "\n",
    "# 2️⃣ Tokenizer: parte el documento en palabras\n",
    "tokenizer = (\n",
    "    Tokenizer()\n",
    "    .setInputCols([\"document\"])         # <- ahora sí, recibe \"document\"\n",
    "    .setOutputCol(\"token\")\n",
    ")\n",
    "\n",
    "# 3️⃣ StopWordsCleaner: elimina stop‑words\n",
    "stopwords_cleaner = (\n",
    "    StopWordsCleaner()\n",
    "    .setInputCols([\"token\"])\n",
    "    .setOutputCol(\"token_sin_stop\")\n",
    "    .setCaseSensitive(False)\n",
    "    .setStopWords([\"y\", \"de\", \"la\", \"the\", \"and\", \"is\", \"es\", \"porque\", \"to\", \"am\", \"el\", \"in\", \"some\"])\n",
    ")\n",
    "\n",
    "# 4️⃣ Finisher: extrae los tokens finales como lista de strings\n",
    "finisher = (\n",
    "    Finisher()\n",
    "    .setInputCols([\"token_sin_stop\"])\n",
    "    .setOutputCols([\"tokens_final\"])\n",
    ")\n",
    "\n",
    "# 5️⃣ Pipeline completo\n",
    "pipeline_stop = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    stopwords_cleaner,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "df_tokens_final = pipeline_stop.fit(df_no_accents).transform(df_no_accents)\n",
    "\n",
    "df_tokens_final.select(\"texto_limpio\", \"tokens_final\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb33bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
