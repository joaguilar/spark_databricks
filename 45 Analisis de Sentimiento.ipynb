{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97383041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==6.0.2 in ./.venv/lib/python3.9/site-packages (6.0.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Requirement already satisfied: wordcloud in ./.venv/lib/python3.9/site-packages (1.9.4)\n",
      "Requirement already satisfied: pypdf2 in ./.venv/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: contractions in ./.venv/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in ./.venv/lib/python3.9/site-packages (from pypdf2) (4.14.1)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in ./.venv/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: anyascii in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spark-nlp==6.0.2 numpy pandas matplotlib seaborn setuptools wordcloud pypdf2 contractions unidecode\n",
    "%pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('./spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max\n",
    "from pyspark.sql.functions import grouping_id, window, explode, to_json, from_json\n",
    "from pyspark.sql.functions import udf, lit, current_timestamp, current_date, date_format\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import PyPDF2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd2c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:15:25 WARN Utils: Your hostname, Joses-MacBook-Air-2.local resolves to a loopback address: 127.0.0.1; using 192.168.100.185 instead (on interface en0)\n",
      "25/07/27 18:15:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/joseaguilar/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/joseaguilar/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp-silicon_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-95ea6012-50bc-4e2e-88ab-4473a7282f38;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp-silicon_2.12;6.0.2 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/joseaguilar/Documents/Development/spark/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in local-m2-cache\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in local-m2-cache\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in local-m2-cache\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in local-m2-cache\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.jsoup#jsoup;1.18.2 in central\n",
      "\tfound jakarta.mail#jakarta.mail-api;2.1.3 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;2.1.3 in central\n",
      "\tfound org.eclipse.angus#angus-mail;2.0.3 in central\n",
      "\tfound org.eclipse.angus#angus-activation;2.0.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.2 in central\n",
      "\tfound org.apache.poi#poi;4.1.2 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.4 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound com.zaxxer#SparseBitSet;1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.2 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound org.apache.poi#poi-scratchpad;4.1.2 in central\n",
      "\tfound org.apache.pdfbox#pdfbox;2.0.28 in central\n",
      "\tfound org.apache.pdfbox#fontbox;2.0.28 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-m1_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.19.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-llamacpp-silicon_2.12;0.1.6 in central\n",
      "\tfound org.jetbrains#annotations;24.1.0 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 in central\n",
      ":: resolution report :: resolve 751ms :: artifacts dl 19ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from local-m2-cache in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from local-m2-cache in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from local-m2-cache in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from local-m2-cache in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-llamacpp-silicon_2.12;0.1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp-silicon_2.12;6.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-m1_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.19.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcom.zaxxer#SparseBitSet;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;2.1.3 from central in [default]\n",
      "\tjakarta.mail#jakarta.mail-api;2.1.3 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.apache.pdfbox#fontbox;2.0.28 from central in [default]\n",
      "\torg.apache.pdfbox#pdfbox;2.0.28 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-scratchpad;4.1.2 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-activation;2.0.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-mail;2.0.3 from central in [default]\n",
      "\torg.jetbrains#annotations;24.1.0 from central in [default]\n",
      "\torg.jsoup#jsoup;1.18.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\tcommons-codec#commons-codec;1.13 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  104  |   0   |   0   |   6   ||   98  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-95ea6012-50bc-4e2e-88ab-4473a7282f38\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 98 already retrieved (0kB/11ms)\n",
      "25/07/27 18:15:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/27 18:15:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/07/27 18:15:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/07/27 18:15:27 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/07/27 18:15:27 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"nlpdemo\") \\\n",
    "#     .config(\"spark.jars.packages\", \n",
    "#             \",\".join([\n",
    "#                 \"com.johnsnowlabs.nlp:spark-nlp_2.12:6.0.2\",\n",
    "#                 \"org.tensorflow:tensorflow-core-platform:1.1.0\"\n",
    "#             ])) \\\n",
    "#     .getOrCreate()\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"nlpdemo\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \",\".join([\n",
    "                \"com.johnsnowlabs.nlp:spark-nlp-silicon_2.12:6.0.2\"\n",
    "            ])) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397f601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0.2\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:15:30 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer\n",
    "\n",
    "print(sparknlp.version())\n",
    "spark = sparknlp.start(apple_silicon=True, memory=\"10G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ae0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+--------------------+\n",
      "|texto                                               |sentimiento_esperado|\n",
      "+----------------------------------------------------+--------------------+\n",
      "|Me encantó la película, estuvo genial!              |positivo            |\n",
      "|Qué mala atención al cliente, estoy muy decepcionado|negativo            |\n",
      "|No está mal, pero podría ser mejor                  |neutral             |\n",
      "|La comida fue exquisita, 100% recomendada           |positivo            |\n",
      "|El producto llegó roto, terrible calidad            |negativo            |\n",
      "+----------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sentimiento = [\n",
    "    # (\"I think Alex Johnson is doing a fantastic job leading the country.\", \"positive\"),\n",
    "    # (\"Alex Johnson's policies are ruining our economy.\", \"negative\"),\n",
    "    # (\"I'm not sure about Alex Johnson's latest speech, it was confusing.\", \"neutral\"),\n",
    "    # (\"The new reforms introduced by Alex Johnson are very promising.\", \"positive\"),\n",
    "    # (\"Alex Johnson seems to care about the people's issues, which is refreshing.\", \"positive\"),\n",
    "    # (\"I am disappointed with Alex Johnson's performance.\", \"negative\"),\n",
    "    # (\"Alex Johnson's leadership style is quite effective.\", \"positive\"),\n",
    "    # (\"The way Alex Johnson handled the recent crisis was commendable.\", \"positive\"),\n",
    "    # (\"I don't trust Alex Johnson's intentions at all.\", \"negative\"),\n",
    "    # (\"Alex Johnson has brought positive changes to the healthcare system.\", \"positive\")\n",
    "    (\"Me encantó la película, estuvo genial!\", \"positivo\"),\n",
    "    (\"Qué mala atención al cliente, estoy muy decepcionado\", \"negativo\"),\n",
    "    (\"No está mal, pero podría ser mejor\", \"neutral\"),\n",
    "    (\"La comida fue exquisita, 100% recomendada\", \"positivo\"),\n",
    "    (\"El producto llegó roto, terrible calidad\", \"negativo\")\n",
    "]\n",
    "df_sentimiento = spark.createDataFrame(data_sentimiento, [\"texto\", \"sentimiento_esperado\"])\n",
    "df_sentimiento.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7516eac",
   "metadata": {},
   "source": [
    "Modelo utilizado: https://sparknlp.org/2021/09/28/classifierdl_bert_sentiment_es.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8629ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labse download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:20:04 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 1.7 GB\n",
      "[OK!]\n",
      "classifierdl_bert_sentiment download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:20:07 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 22.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.annotator import ClassifierDLModel, UniversalSentenceEncoder, BertForSequenceClassification\n",
    "from sparknlp.annotator import BertSentenceEmbeddings\n",
    "from sparknlp.base import DocumentAssembler, LightPipeline\n",
    "\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"texto\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "embeddings = BertSentenceEmbeddings\\\n",
    "    .pretrained('labse', 'xx') \\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentClassifier = ClassifierDLModel.pretrained(\"classifierdl_bert_sentiment\", \"es\") \\\n",
    "  .setInputCols([\"sentence_embeddings\"]) \\\n",
    "  .setOutputCol(\"sentiment_result\")\n",
    "\n",
    "fr_sentiment_pipeline = Pipeline(stages=[document, embeddings, sentimentClassifier])\n",
    "\n",
    "# light_pipeline = LightPipeline(fr_sentiment_pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
    "\n",
    "# result1 = light_pipeline.annotate(\"Estoy seguro de que esta vez pasará la entrevista.\")\n",
    "\n",
    "# result2 = light_pipeline.annotate(\"Soy una persona que intenta desayunar todas las mañanas sin falta.\")\n",
    "\n",
    "# result3 = light_pipeline.annotate(\"No estoy seguro de si mi salario mensual es suficiente para vivir.\")\n",
    "\n",
    "# print(result1[\"class\"], result2[\"class\"], sep = \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c2c9992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+--------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|texto                                               |sentimiento_esperado|sentiment_result                                                                                                             |\n",
      "+----------------------------------------------------+--------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|Me encantó la película, estuvo genial!              |positivo            |[{category, 0, 37, POSITIVE, {sentence -> 0, POSITIVE -> 0.999985, NEGATIVE -> 1.3858803E-5, NEUTRAL -> 1.1341377E-6}, []}]  |\n",
      "|Qué mala atención al cliente, estoy muy decepcionado|negativo            |[{category, 0, 51, NEGATIVE, {sentence -> 0, POSITIVE -> 0.09921264, NEGATIVE -> 0.9007314, NEUTRAL -> 5.591754E-5}, []}]    |\n",
      "|No está mal, pero podría ser mejor                  |neutral             |[{category, 0, 33, POSITIVE, {sentence -> 0, POSITIVE -> 0.99248236, NEGATIVE -> 0.007432651, NEUTRAL -> 8.5004685E-5}, []}] |\n",
      "|La comida fue exquisita, 100% recomendada           |positivo            |[{category, 0, 40, POSITIVE, {sentence -> 0, POSITIVE -> 0.99998605, NEGATIVE -> 8.882163E-6, NEUTRAL -> 5.014341E-6}, []}]  |\n",
      "|El producto llegó roto, terrible calidad            |negativo            |[{category, 0, 39, NEGATIVE, {sentence -> 0, POSITIVE -> 0.0038367498, NEGATIVE -> 0.99608684, NEUTRAL -> 7.6434844E-5}, []}]|\n",
      "+----------------------------------------------------+--------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = fr_sentiment_pipeline.fit(df_sentimiento).transform(df_sentimiento)\n",
    "df_result.select(\"texto\", \"sentimiento_esperado\", \"sentiment_result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://sparknlp.org/2021/09/28/classifierdl_bert_sentiment_es.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6f90c",
   "metadata": {},
   "source": [
    "[Model Hub](https://sparknlp.org/models?task=Text+Classification)\n",
    "\n",
    "Modelos: https://sparknlp.org/models?task=Text+Classification&type=model&supported=1&annotator=BertForSequenceClassification&language=en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da22100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:22:43 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:43 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/07/27 18:22:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/07/27 18:22:43 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:43 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:46 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:47 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:47 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|               texto|sentimiento_esperado|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|Me encantó la pel...|            positivo|       1.0|\n",
      "|Qué mala atención...|            negativo|       0.0|\n",
      "|No está mal, pero...|             neutral|       2.0|\n",
      "|La comida fue exq...|            positivo|       1.0|\n",
      "|El producto llegó...|            negativo|       0.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:22:47 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:47 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/07/27 18:22:47 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Convertir texto a TF-IDF manualmente para entrenar modelo (Spark ML pipeline)\n",
    "tokenizer = Tokenizer(inputCol=\"texto\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\")\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Necesitamos índice numérico para las etiquetas de sentimiento\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"sentimiento_esperado\", outputCol=\"label\").fit(df_sentimiento)\n",
    "df_ml = indexer.transform(df_sentimiento)\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, hashingTF, idf, lr])\n",
    "model_lr = pipeline_lr.fit(df_ml)\n",
    "df_pred = model_lr.transform(df_ml)\n",
    "df_pred.select(\"texto\", \"sentimiento_esperado\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae653df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de entrenamiento: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:23:26 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "# Calcular la exactitud del modelo\n",
    "correctas = df_pred.filter(expr(\"prediction == label\")).count()\n",
    "total = df_pred.count()\n",
    "print(f\"Exactitud en el conjunto de entrenamiento: {correctas/total:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
