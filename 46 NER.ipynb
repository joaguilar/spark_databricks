{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97383041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==6.0.2 in ./.venv/lib/python3.9/site-packages (6.0.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Requirement already satisfied: wordcloud in ./.venv/lib/python3.9/site-packages (1.9.4)\n",
      "Requirement already satisfied: pypdf2 in ./.venv/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: contractions in ./.venv/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in ./.venv/lib/python3.9/site-packages (from pypdf2) (4.14.1)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in ./.venv/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: anyascii in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in ./.venv/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spark-nlp==6.0.2 numpy pandas matplotlib seaborn setuptools wordcloud pypdf2 contractions unidecode\n",
    "%pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('./spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max\n",
    "from pyspark.sql.functions import grouping_id, window, explode, to_json, from_json\n",
    "from pyspark.sql.functions import udf, lit, current_timestamp, current_date, date_format\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "import PyPDF2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd2c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:29:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"nlpdemo\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \",\".join([\n",
    "                \"com.johnsnowlabs.nlp:spark-nlp-silicon_2.12:6.0.2\"\n",
    "            ])) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397f601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0.2\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:29:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, Normalizer\n",
    "\n",
    "print(sparknlp.version())\n",
    "spark = sparknlp.start(apple_silicon=True, memory=\"8G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87ae0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un conjunto de textos para analizar\n",
    "texts = [\n",
    "    (\"Apple Inc. is looking to buy a startup in the United States.\",),\n",
    "    (\"Barack Obama was the 44th President of the United States.\",),\n",
    "    (\"Elon Musk founded SpaceX, an aerospace manufacturer and space transportation company.\",),\n",
    "    (\"The Amazon rainforest is the largest tropical rainforest in the world.\",),\n",
    "    (\"Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\",)\n",
    "]\n",
    "\n",
    "# Crear un DataFrame\n",
    "df_ner = spark.createDataFrame(texts, [\"texto\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7516eac",
   "metadata": {},
   "source": [
    "Modelo utilizado: https://sparknlp.org/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html \n",
    "\n",
    "Modelo Embeddings: https://sparknlp.org/2020/01/22/glove_100d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8629ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:34:44 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 145.3 MB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:34:44 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/07/27 18:34:44 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[ \\ ]Download done! Loading the resource.\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/27 18:34:57 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------------------+\n",
      "|result             |metadata                                  |\n",
      "+-------------------+------------------------------------------+\n",
      "|Apple Inc          |{entity -> ORG, sentence -> 0, chunk -> 0}|\n",
      "|United States      |{entity -> LOC, sentence -> 0, chunk -> 1}|\n",
      "|Barack Obama       |{entity -> PER, sentence -> 0, chunk -> 0}|\n",
      "|United States      |{entity -> LOC, sentence -> 0, chunk -> 1}|\n",
      "|Elon Musk          |{entity -> ORG, sentence -> 0, chunk -> 0}|\n",
      "|SpaceX             |{entity -> ORG, sentence -> 0, chunk -> 1}|\n",
      "|Amazon             |{entity -> LOC, sentence -> 0, chunk -> 0}|\n",
      "|Google             |{entity -> ORG, sentence -> 0, chunk -> 0}|\n",
      "|Larry Page         |{entity -> PER, sentence -> 0, chunk -> 1}|\n",
      "|Sergey Brin        |{entity -> PER, sentence -> 0, chunk -> 2}|\n",
      "|Ph.D               |{entity -> ORG, sentence -> 0, chunk -> 3}|\n",
      "|Stanford University|{entity -> ORG, sentence -> 0, chunk -> 4}|\n",
      "+-------------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import Tokenizer, NerDLModel, WordEmbeddings, NerConverter, WordEmbeddingsModel\n",
    "\n",
    "document_assembler = DocumentAssembler().setInputCol(\"texto\").setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = sparknlp.annotator.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "    \n",
    "tokenizer = Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "\n",
    "# Use WordEmbeddings with glove_100d to match ner_dl requirements\n",
    "embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"]).setOutputCol(\"embeddings\")\n",
    "    \n",
    "ner_model = NerDLModel.pretrained(\"ner_dl\", \"en\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]).setOutputCol(\"ner\")\n",
    "    \n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]).setOutputCol(\"entidades\")\n",
    "\n",
    "pipeline_ner = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter])\n",
    "resultado_ner = pipeline_ner.fit(df_ner).transform(df_ner)\n",
    "resultado_ner.select(\"texto\", explode(\"entidades\").alias(\"entidad\"))\\\n",
    "             .select(\"entidad.result\", \"entidad.metadata\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c9992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4d7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da22100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae653df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
